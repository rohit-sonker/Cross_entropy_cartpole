{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "PERCENTILE = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, obs_size, hidden_size, n_actions):\n",
    "        super(Net,self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "                nn.Linear(obs_size, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_size, n_actions)\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.net(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Episode = namedtuple('Episode', field_names=['reward', 'steps'])\n",
    "EpisodeStep = namedtuple('EpisodeStep', field_names=['observation','action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([1.0,2.0,3.0,4])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xn = x.data.numpy()[0]\n",
    "smm = nn.Softmax(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0321, 0.0871, 0.2369, 0.6439])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = smm(x)\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0320586 , 0.08714432, 0.23688284, 0.6439143 ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(env, net, batch_size):\n",
    "    batch = []\n",
    "    episode_reward = 0.0\n",
    "    episode_steps = []\n",
    "    obs=env.reset()\n",
    "    sm = nn.Softmax(dim=1)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "#         env.render()\n",
    "        \n",
    "        obs_v = torch.FloatTensor([obs])\n",
    "        act_probs_v = sm(net(obs_v))\n",
    "        act_probs = act_probs_v.data.numpy()[0]\n",
    "        \n",
    "        action = np.random.choice(len(act_probs), p = act_probs)\n",
    "        next_obs, rew, is_done, _ = env.step(action)\n",
    "        \n",
    "        episode_reward+=rew\n",
    "        episode_steps.append(EpisodeStep(observation = obs, action = action))\n",
    "        \n",
    "        if is_done:\n",
    "            \n",
    "#             print(episode_reward)\n",
    "            \n",
    "            batch.append(Episode(reward = episode_reward, steps = episode_steps))\n",
    "            episode_reward = 0.0\n",
    "            episode_steps=[]\n",
    "            next_obs = env.reset()\n",
    "            if len(batch)==batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "             \n",
    "        obs = next_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_batch(batch, percentile):\n",
    "    rewards = list(map(lambda s:s.reward, batch))\n",
    "    reward_bound = np.percentile(rewards, percentile)\n",
    "    reward_mean = float(np.mean(rewards))\n",
    "    train_obs = []\n",
    "    train_act = []\n",
    "    for example in batch:\n",
    "        if example.reward<reward_bound:\n",
    "            continue\n",
    "        train_obs.extend(map(lambda step: step.observation, example.steps))\n",
    "        train_act.extend(map(lambda step: step.action, example.steps))\n",
    "    \n",
    "    train_obs_v = torch.FloatTensor(train_obs)\n",
    "    train_act_v = torch.LongTensor(train_act)\n",
    "    return train_obs_v, train_act_v, reward_bound, reward_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main run\n",
    "\n",
    "env = gym.make(\"CartPole-v0\")\n",
    "obs_size = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "net = Net(obs_size, HIDDEN_SIZE, n_actions)\n",
    "objective = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(params = net.parameters(), lr=0.01)\n",
    "writer = SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: loss=0.685, reward_mean=21.6, reward_bound=25.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute '_check_caffe2_blob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-b7374d4a4335>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%d: loss=%.3f, reward_mean=%.1f, reward_bound=%.1f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0miter_no\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward_b\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"loss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_v\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"reward_bound\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"reward_mean\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miter_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\gym\\lib\\site-packages\\tensorboardX\\writer.py\u001b[0m in \u001b[0;36madd_scalar\u001b[1;34m(self, tag, scalar_value, global_step, walltime)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m         \"\"\"\n\u001b[1;32m--> 402\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_caffe2_blob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalar_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    403\u001b[0m             \u001b[0mscalar_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFetchBlob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscalar_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         self._get_file_writer().add_summary(\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute '_check_caffe2_blob'"
     ]
    }
   ],
   "source": [
    "#loop through\n",
    "for iter_no, batch in enumerate(iterate_batches(env, net, BATCH_SIZE)):\n",
    "    obs_v, act_v, reward_b, reward_m = filter_batch(batch, PERCENTILE)\n",
    "    optimizer.zero_grad()\n",
    "    action_scores_v = net(obs_v)\n",
    "    loss_v = objective(action_scores_v, act_v)\n",
    "    loss_v.backward()\n",
    "    optimizer.step()\n",
    "    print(\"%d: loss=%.3f, reward_mean=%.1f, reward_bound=%.1f\" % (iter_no, loss_v.item(), reward_m, reward_b))\n",
    "    writer.add_scalar(\"loss\", loss_v.item(), iter_no)\n",
    "    writer.add_scalar(\"reward_bound\", reward_b, iter_no)\n",
    "    writer.add_scalar(\"reward_mean\", reward_m, iter_no)\n",
    "    \n",
    "    if reward_m > 199:\n",
    "        print(\"Solved!\")\n",
    "        break\n",
    "        writer.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_trained = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_obs = env.observation_space.sample()\n",
    "sample_obs_v = torch.FloatTensor([sample_obs])\n",
    "sm = nn.Softmax(dim=1)\n",
    "sample_action_prob = sm(net_trained(sample_obs_v))\n",
    "sample_action_probx = sm(net(sample_obs_v))\n",
    "sample_action_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm=nn.Softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7086e+00, -2.5159e+38, -1.3974e-01,  1.7519e+38]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_obs = env.observation_space.sample()\n",
    "sample_obs_v = torch.FloatTensor([sample_obs])\n",
    "sample_obs_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 129666012503614031267066647994536296448.,\n",
       "         -128649620393555838758781803338091462656.]],\n",
       "       grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_trained(sample_obs_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-293982736963021820106449867453117759488.,\n",
       "          293938845828639517891652445601334820864.]],\n",
       "       grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(sample_obs_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm(net_trained(sample_obs_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a = sm(net(sample_obs_v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.data.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(obs, net):\n",
    "    \n",
    "    obs_v = torch.FloatTensor([obs])\n",
    "    act_probs_v = sm(net(obs_v))\n",
    "    act_probs = act_probs_v.data.numpy()[0]\n",
    "\n",
    "    action = np.random.choice(len(act_probs), p = act_probs)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 4])\n",
      "tensor([[-0.4165, -0.3100, -0.3523,  0.2744],\n",
      "        [ 0.1138,  0.4158, -0.1633,  0.0167],\n",
      "        [ 0.3345,  0.1123, -0.0536, -0.3350],\n",
      "        [ 0.3959, -0.0379, -0.0983, -0.5723],\n",
      "        [ 0.2356, -0.2427,  0.7050,  0.5805],\n",
      "        [ 0.3378,  0.5010,  0.2678,  0.3262],\n",
      "        [-0.1047, -0.1973,  0.0860,  0.6086],\n",
      "        [ 0.1179,  0.4989,  0.0466, -0.1225],\n",
      "        [-0.3666,  0.5163, -0.1876,  0.2111],\n",
      "        [ 0.3868,  0.1244, -0.2217, -0.4546],\n",
      "        [-0.0985, -0.2412,  0.6035,  0.5090],\n",
      "        [ 0.3549,  0.4618, -0.6207, -0.2671],\n",
      "        [ 0.1531, -0.0989, -0.5064,  0.3381],\n",
      "        [ 0.3141,  0.1692,  0.0310, -0.3657],\n",
      "        [-0.0933,  0.4379, -0.1776, -0.3629],\n",
      "        [-0.4082,  0.0807, -0.1323, -0.3077],\n",
      "        [ 0.0256, -0.5769, -0.5382, -0.2351],\n",
      "        [-0.4523, -0.2651,  0.2338,  0.4431],\n",
      "        [ 0.0078, -0.3460, -0.4165, -0.5049],\n",
      "        [ 0.2957, -0.3941, -0.5956, -0.5030],\n",
      "        [-0.2394, -0.1065, -0.7125, -0.5746],\n",
      "        [ 0.2714, -0.2874,  0.4163,  0.2780],\n",
      "        [-0.0397, -0.5775, -0.1539, -0.4382],\n",
      "        [ 0.0997,  0.3399,  0.7600,  0.6615],\n",
      "        [-0.3738, -0.3020,  0.5510,  0.0172],\n",
      "        [-0.0709,  0.0039,  0.1703, -0.1472],\n",
      "        [ 0.2392, -0.4810, -0.1166, -0.1265],\n",
      "        [ 0.4159,  0.2224, -0.0968, -0.4517],\n",
      "        [-0.0031, -0.3282, -0.0015, -0.3505],\n",
      "        [-0.2939, -0.2553, -0.3538, -0.4515],\n",
      "        [-0.3317,  0.0812,  0.2407,  0.1925],\n",
      "        [ 0.0854, -0.1057,  0.4026,  0.4450],\n",
      "        [-0.4482,  0.4406,  0.3847, -0.0497],\n",
      "        [-0.3732, -0.4039,  0.5583, -0.0212],\n",
      "        [ 0.0710, -0.4282, -0.6007,  0.0123],\n",
      "        [-0.0535,  0.0099, -0.7309, -0.0728],\n",
      "        [-0.1778, -0.1135, -0.0483, -0.5597],\n",
      "        [ 0.3803,  0.0229, -0.0540, -0.3101],\n",
      "        [-0.0472, -0.2840,  0.3140,  0.1851],\n",
      "        [ 0.2296, -0.3985,  0.6258,  0.2154],\n",
      "        [ 0.0269,  0.1624, -0.3774, -0.3066],\n",
      "        [-0.1853,  0.4953,  0.3977, -0.2564],\n",
      "        [ 0.0472, -0.0208,  0.1128,  0.1092],\n",
      "        [-0.2568, -0.3803, -0.6448,  0.1244],\n",
      "        [ 0.1262, -0.4821,  0.4602,  0.1960],\n",
      "        [-0.0347,  0.4525, -0.5816,  0.0362],\n",
      "        [ 0.2493,  0.4260, -0.4862, -0.1701],\n",
      "        [ 0.3967, -0.0013, -0.4915, -0.3741],\n",
      "        [-0.4952,  0.0608, -0.3889, -0.5302],\n",
      "        [ 0.2470, -0.2791,  0.0007, -0.3824],\n",
      "        [ 0.3861, -0.1545,  0.1146, -0.5190],\n",
      "        [-0.0152,  0.0720,  0.0334, -0.1656],\n",
      "        [-0.3234, -0.2844, -0.3956, -0.1041],\n",
      "        [ 0.4929,  0.2010,  0.2733, -0.1109],\n",
      "        [-0.4633,  0.2295,  0.1810, -0.5599],\n",
      "        [-0.3585,  0.4549,  0.2419,  0.3335],\n",
      "        [-0.4257, -0.2163, -0.1193,  0.5026],\n",
      "        [ 0.3724,  0.0672,  0.3577,  0.3498],\n",
      "        [ 0.2605,  0.0761,  0.4138,  0.2089],\n",
      "        [-0.2220, -0.3705, -0.2535, -0.3624],\n",
      "        [ 0.4951,  0.4182, -0.1308, -0.0364],\n",
      "        [-0.4250, -0.0898,  0.0773, -0.3969],\n",
      "        [-0.4265,  0.0429,  0.1364, -0.1400],\n",
      "        [ 0.1432, -0.0608, -0.3760, -0.6461],\n",
      "        [-0.5055, -0.1105,  0.4422,  0.0791],\n",
      "        [ 0.1693,  0.5182,  0.7086,  0.6519],\n",
      "        [-0.3001, -0.4374,  0.0463, -0.5271],\n",
      "        [ 0.1733, -0.3957,  0.4135, -0.3660],\n",
      "        [ 0.0350,  0.1401, -0.4001, -0.5218],\n",
      "        [ 0.4083,  0.2068,  0.6598,  0.5361],\n",
      "        [ 0.4164,  0.2081,  0.3101,  0.0455],\n",
      "        [-0.4176, -0.2205, -0.4045,  0.1258],\n",
      "        [ 0.3379,  0.0998,  0.0527,  0.0358],\n",
      "        [-0.2793, -0.2536,  0.5518,  0.4953],\n",
      "        [ 0.3130,  0.0623,  0.4786,  0.2160],\n",
      "        [ 0.3045, -0.3929, -0.5084,  0.3664],\n",
      "        [-0.4460,  0.2008, -0.5326, -0.5680],\n",
      "        [-0.0362, -0.4455, -0.3803,  0.1033],\n",
      "        [ 0.1160,  0.3434, -0.0676,  0.5130],\n",
      "        [-0.0860, -0.2609,  0.5349, -0.0718],\n",
      "        [ 0.5092, -0.1346, -0.1717, -0.2131],\n",
      "        [-0.4327,  0.1934, -0.1771, -0.2241],\n",
      "        [ 0.3512,  0.2427, -0.1504, -0.6093],\n",
      "        [-0.1743,  0.5001,  0.3584,  0.0810],\n",
      "        [ 0.0711,  0.0383,  0.1754, -0.4730],\n",
      "        [-0.2806, -0.2141,  0.1849, -0.5388],\n",
      "        [-0.4317, -0.2249,  0.1579,  0.0458],\n",
      "        [-0.2411, -0.0584,  0.3260,  0.3290],\n",
      "        [ 0.4282, -0.1475,  0.2538,  0.2848],\n",
      "        [ 0.2333,  0.2316,  0.3672,  0.5372],\n",
      "        [-0.0014, -0.0425, -0.1568,  0.3397],\n",
      "        [ 0.1139, -0.2382, -0.1345, -0.0713],\n",
      "        [ 0.4013,  0.0619,  0.3171, -0.2648],\n",
      "        [-0.3002, -0.0246, -0.0984, -0.5012],\n",
      "        [-0.2468, -0.4293,  0.5332,  0.4457],\n",
      "        [-0.0661, -0.2257,  0.3199, -0.2953],\n",
      "        [-0.4352, -0.0737, -0.1108,  0.3316],\n",
      "        [ 0.2067,  0.1418,  0.1356, -0.1390],\n",
      "        [ 0.2951,  0.0090,  0.2366,  0.3465],\n",
      "        [ 0.3929,  0.2928,  0.2553,  0.5028],\n",
      "        [ 0.4498, -0.1381, -0.3177, -0.5036],\n",
      "        [-0.1839,  0.3772,  0.6432,  0.1739],\n",
      "        [ 0.2445,  0.3099,  0.4853,  0.1247],\n",
      "        [-0.1050,  0.0335, -0.0911, -0.0248],\n",
      "        [ 0.4648, -0.3965,  0.1327,  0.3210],\n",
      "        [ 0.0145, -0.2191, -0.2388,  0.2297],\n",
      "        [-0.3656,  0.1965,  0.5269,  0.5984],\n",
      "        [-0.2107, -0.1492,  0.2682,  0.2565],\n",
      "        [ 0.1795,  0.4487,  0.4264,  0.3982],\n",
      "        [-0.3066,  0.2350,  0.0402, -0.1064],\n",
      "        [ 0.2533, -0.3057,  0.1319, -0.0389],\n",
      "        [ 0.0987, -0.2243, -0.0094,  0.4032],\n",
      "        [ 0.3134,  0.3754, -0.4203, -0.0032],\n",
      "        [-0.2872,  0.3618,  0.7183,  0.5095],\n",
      "        [-0.0677,  0.3291, -0.1810,  0.3026],\n",
      "        [-0.0325,  0.2747, -0.0125, -0.2594],\n",
      "        [-0.2003,  0.0748, -0.4327, -0.5472],\n",
      "        [ 0.4156,  0.0217,  0.1326, -0.2789],\n",
      "        [ 0.1917, -0.4774, -0.2142, -0.1379],\n",
      "        [-0.4758, -0.2947, -0.1391,  0.5132],\n",
      "        [ 0.0190,  0.5181,  0.5740,  0.3298],\n",
      "        [-0.4220, -0.0325, -0.4549, -0.1968],\n",
      "        [ 0.2244, -0.0502, -0.5791, -0.6048],\n",
      "        [-0.2203, -0.4871,  0.0304,  0.4873],\n",
      "        [ 0.0756, -0.2335,  0.2788,  0.0553],\n",
      "        [ 0.4151,  0.4116, -0.2704,  0.1403],\n",
      "        [-0.2504, -0.0778,  0.1522,  0.0621],\n",
      "        [-0.4073, -0.1521,  0.2785,  0.0362]])\n",
      "torch.Size([128])\n",
      "tensor([-0.0001, -0.1401, -0.4832, -0.1009,  0.0210,  0.1503,  0.2648, -0.1756,\n",
      "         0.4603, -0.4324,  0.4497,  0.1775, -0.3035, -0.3738, -0.0759, -0.1764,\n",
      "        -0.0896,  0.0687,  0.1046,  0.2644,  0.4683, -0.2908, -0.1458,  0.1518,\n",
      "         0.4538, -0.2589,  0.0750,  0.3700,  0.3171,  0.3131,  0.0606,  0.0942,\n",
      "        -0.1558,  0.2137,  0.4482,  0.4161,  0.0837,  0.3801,  0.0924, -0.0877,\n",
      "         0.1965, -0.4555,  0.4733,  0.0499, -0.4883, -0.1685,  0.2207,  0.1581,\n",
      "        -0.2117,  0.1143,  0.0132, -0.2573,  0.2557, -0.3810, -0.4403, -0.1959,\n",
      "         0.1317,  0.0100, -0.0421, -0.3053, -0.0072, -0.3538,  0.4303,  0.4738,\n",
      "        -0.3756,  0.2648,  0.2292, -0.3572,  0.3830,  0.2195,  0.1617, -0.2430,\n",
      "        -0.4596, -0.2654, -0.4265, -0.1762,  0.0102,  0.0661,  0.2303, -0.2113,\n",
      "        -0.2958,  0.1390,  0.1580,  0.4637, -0.1186,  0.0788, -0.0331,  0.1873,\n",
      "         0.4520,  0.2728,  0.0270, -0.2437, -0.4167, -0.4002, -0.4009, -0.4414,\n",
      "        -0.0265, -0.1079,  0.1737,  0.0861,  0.3296,  0.2355, -0.1471, -0.2802,\n",
      "         0.0036, -0.0855,  0.0843,  0.4218,  0.1043,  0.2051, -0.2635, -0.0650,\n",
      "         0.0899,  0.1748,  0.3239,  0.3914,  0.1313,  0.3943, -0.1688,  0.4767,\n",
      "         0.2828, -0.2956,  0.2255, -0.2019, -0.2651, -0.4858,  0.2791,  0.3525])\n",
      "torch.Size([2, 128])\n",
      "tensor([[ 0.0231,  0.0201,  0.0153,  0.1682, -0.1383, -0.1172, -0.1192, -0.0385,\n",
      "         -0.0509,  0.1199, -0.0097,  0.1052,  0.0237,  0.0839, -0.0261,  0.1172,\n",
      "          0.1486,  0.0265,  0.2017,  0.2084,  0.0898,  0.0378,  0.0400, -0.1566,\n",
      "         -0.0441, -0.0257,  0.0764,  0.0303,  0.1482,  0.0837, -0.1512, -0.0185,\n",
      "         -0.0395, -0.0724,  0.0799, -0.0315,  0.1929, -0.0239, -0.0136, -0.0853,\n",
      "          0.1549,  0.0592,  0.0371,  0.0887,  0.0478,  0.0600, -0.0169,  0.1920,\n",
      "          0.0903,  0.0401,  0.0106,  0.0376,  0.0518,  0.0719,  0.0225, -0.1822,\n",
      "         -0.1196, -0.0226, -0.0095,  0.0955,  0.0955, -0.0110, -0.0085,  0.1810,\n",
      "         -0.1051, -0.1349,  0.1737, -0.0423,  0.0138, -0.1543,  0.0018, -0.0284,\n",
      "          0.0506, -0.0798, -0.0810, -0.0182,  0.0876,  0.0810, -0.1059, -0.0437,\n",
      "          0.1018,  0.0335,  0.0379, -0.0138,  0.1152,  0.1395, -0.0633, -0.1653,\n",
      "         -0.1151, -0.0846, -0.0670,  0.0545, -0.0163, -0.0597, -0.0401, -0.0313,\n",
      "         -0.0532, -0.0398, -0.1384, -0.0708,  0.1459, -0.0890, -0.0556, -0.0373,\n",
      "         -0.0755, -0.0286, -0.1522, -0.0707, -0.2097,  0.0122,  0.0103, -0.1233,\n",
      "          0.0885, -0.1752, -0.0178,  0.0422,  0.0569,  0.0358,  0.0245, -0.0922,\n",
      "         -0.1240,  0.0259,  0.1203, -0.1178, -0.0293,  0.0748, -0.0835, -0.0182],\n",
      "        [ 0.0431, -0.0122,  0.0394, -0.0959,  0.0015,  0.0532,  0.0331, -0.0502,\n",
      "          0.0021, -0.0925,  0.0979, -0.0781, -0.0316,  0.0016, -0.0662, -0.0063,\n",
      "         -0.0787,  0.1031, -0.2284, -0.1065, -0.0772, -0.0025, -0.1345,  0.2078,\n",
      "          0.0064,  0.0677, -0.0589, -0.0145, -0.0386, -0.1183,  0.1984,  0.0557,\n",
      "         -0.0264,  0.0048, -0.0009, -0.1175, -0.0493, -0.0764,  0.1223,  0.0498,\n",
      "         -0.0897, -0.0181, -0.0382, -0.0430,  0.0794, -0.0782, -0.1164, -0.1932,\n",
      "         -0.0883, -0.0636, -0.1229,  0.0756, -0.0430, -0.0741, -0.0303,  0.1382,\n",
      "         -0.0044,  0.0807,  0.0532, -0.0267,  0.0641, -0.0448, -0.0033, -0.0305,\n",
      "          0.0476,  0.1695, -0.1949, -0.0254, -0.1600,  0.1042,  0.0830, -0.0341,\n",
      "         -0.0133, -0.0090,  0.1061, -0.0238, -0.0514,  0.0541,  0.0973,  0.0624,\n",
      "         -0.0787, -0.0709, -0.1587,  0.0278, -0.1237, -0.0060, -0.0299,  0.0101,\n",
      "          0.0097,  0.0805,  0.0905,  0.0749,  0.0695, -0.0947,  0.1125, -0.0605,\n",
      "          0.0591, -0.0234,  0.1709,  0.1210, -0.1133,  0.0722,  0.0378, -0.0501,\n",
      "          0.1312,  0.0076,  0.2033,  0.0564,  0.1572, -0.0423,  0.0850, -0.0334,\n",
      "         -0.1020,  0.2352,  0.0641, -0.0718, -0.1230, -0.0032, -0.0396, -0.0091,\n",
      "          0.0898,  0.0249, -0.1229,  0.0697, -0.0305,  0.0230,  0.0602,  0.0747]])\n",
      "torch.Size([2])\n",
      "tensor([0.0200, 0.0351])\n"
     ]
    }
   ],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.data.shape)\n",
    "    print(param.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0  Total Reward =  200.0  Total Steps =  200\n",
      "iter 1  Total Reward =  200.0  Total Steps =  200\n",
      "iter 2  Total Reward =  200.0  Total Steps =  200\n",
      "iter 3  Total Reward =  198.0  Total Steps =  198\n",
      "iter 4  Total Reward =  200.0  Total Steps =  200\n",
      "iter 5  Total Reward =  200.0  Total Steps =  200\n",
      "iter 6  Total Reward =  200.0  Total Steps =  200\n",
      "iter 7  Total Reward =  200.0  Total Steps =  200\n",
      "iter 8  Total Reward =  200.0  Total Steps =  200\n",
      "iter 9  Total Reward =  200.0  Total Steps =  200\n",
      "iter 10  Total Reward =  200.0  Total Steps =  200\n",
      "iter 11  Total Reward =  200.0  Total Steps =  200\n",
      "iter 12  Total Reward =  200.0  Total Steps =  200\n",
      "iter 13  Total Reward =  200.0  Total Steps =  200\n",
      "iter 14  Total Reward =  200.0  Total Steps =  200\n",
      "iter 15  Total Reward =  200.0  Total Steps =  200\n",
      "avg rew =  199.875\n"
     ]
    }
   ],
   "source": [
    "# playing with trained agent\n",
    "total_reward_a = []\n",
    "total_steps = 0\n",
    "# obs = env.reset()\n",
    "sm = nn.Softmax(dim=1)\n",
    "\n",
    "for i in range(BATCH_SIZE):\n",
    "    total_reward = 0.0\n",
    "    total_steps = 0\n",
    "    obs = env.reset()\n",
    "    while True:\n",
    "        env.render()\n",
    "        action = get_action(obs, net_trained)\n",
    "#         action = env.action_space.sample()\n",
    "        next_obs, rew, is_done, _ = env.step(action)\n",
    "        total_reward+=rew\n",
    "        total_steps+=1\n",
    "        if is_done:\n",
    "            print(\"iter\",i,\" Total Reward = \",total_reward,\" Total Steps = \", total_steps)            \n",
    "            total_reward_a.append(total_reward)\n",
    "            break\n",
    "        obs=next_obs\n",
    "\n",
    "print('avg rew = ',sum(total_reward_a)/BATCH_SIZE)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
